# Back-propogation-using-Machine-learning

-	The Backpropagation algorithm is used for the minimum value of the error function in weight space using a technique which is as called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem.

- Back-propagation is the essence of neural network training. It is the method of fine-tuning the weights of a neural network based on the error rate obtained in the previous iteration. The objective of Back-propagation is to reduce error rates and to make the model reliable by increasing its generalization
